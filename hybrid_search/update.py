# hybrid_search/update.py

import time
import os
from datetime import datetime, timezone
from typing import Dict, Any

from hybrid_search import database, confluence, embed, chunk
from hybrid_search.utils import html_to_text, get_redis_client, logger, parse_datetime, format_datetime, Config


class UpdateDatabase:
    def __init__(self):
        self.db = database.Database()
        self.confluence_api = confluence.ConfluenceAPI()
        self.chunker = chunk.SemanticChunk()
        self.embedder = embed.Embed()
        self.redis = get_redis_client()
        logger.info("‚úÖ UpdateDatabase –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def update_page(self, page_id: str, page_metadata: Dict[str, Any] = None) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            page_data = self.confluence_api.get_page_full(page_id)
            html_data = page_data['content']
            base_metadata = page_data['metadata'] if page_metadata is None else page_metadata

            text = html_to_text(html_data)
            if not text.strip():
                logger.warning(f"‚ö†Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id} –ø—É—Å—Ç–∞—è")
                return False

            # –ß–∞–Ω–∫–∏–Ω–≥
            chunks = self.chunker.split(text)
            total_chunks = len(chunks)

            for num, chunk_text in enumerate(chunks):
                # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
                dense_vector = self.embedder.embed_text(chunk_text)
                sparse_vector = self.embedder.embed_sparse(chunk_text)

                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —á–∞–Ω–∫–∞
                chunk_id = f"{page_id}-{num}"

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞
                chunk_metadata = {
                    **base_metadata,
                    'chunk_index': num,
                    'total_chunks': total_chunks
                }

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB
                self.db.upsert_page(chunk_id, dense_vector, sparse_vector, chunk_text, chunk_metadata)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            current_time = datetime.now(timezone.utc)
            self.redis.setex(f'update_time:{page_id}', 86400 * 30, format_datetime(current_time))

            logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {total_chunks} —á–∞–Ω–∫–æ–≤")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_id}: {e}")
            return False

    def load_all(self):
        """–ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ Confluence...")

        space_id = self.confluence_api.get_space_id()
        pages = self.confluence_api.get_page_ids(space_id)
        total = len(pages)

        # –°–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è BM25
        logger.info(f"üìö –°–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è BM25 (0/{total})...")
        all_texts = []
        page_data_cache = {}

        for idx, (page_id, page_info) in enumerate(pages.items(), 1):
            # ‚úÖ –ó–ê–©–ò–¢–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø page_info
            if not isinstance(page_info, dict):
                logger.error(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: page_info –∏–º–µ–µ—Ç —Ç–∏–ø {type(page_info)}")
                continue

            try:
                full_data = self.confluence_api.get_page_full(page_id)

                # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ full_data ‚Äî dict
                if not isinstance(full_data, dict):
                    logger.error(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: get_page_full –≤–µ—Ä–Ω—É–ª {type(full_data)}")
                    continue

                text = html_to_text(full_data.get('content', ''))

                if text.strip():
                    all_texts.append(text)
                    page_data_cache[page_id] = {
                        'text': text,
                        'metadata': full_data.get('metadata', {})
                    }

                if idx % 100 == 0 or idx == total:
                    logger.info(f"üìö –°–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤: {idx}/{total} ({100 * idx // total}%)")

            except Exception as e:
                logger.error(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: {e}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25
        if all_texts:
            logger.info(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25 –Ω–∞ {len(all_texts)} –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö...")
            self.embedder.fit_bm25(all_texts)

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        logger.info("üì• –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
        for idx, (page_id, page_info) in enumerate(pages.items(), 1):
            # ‚úÖ again –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞
            if not isinstance(page_info, dict):
                logger.warning(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: page_info –Ω–µ dict")
                continue

            logger.info(f"üì• [{idx}/{total}] {page_info.get('title', page_id)}")

            if page_id in page_data_cache:
                text = page_data_cache[page_id]['text']
                metadata = page_data_cache[page_id]['metadata']
            else:
                try:
                    full_data = self.confluence_api.get_page_full(page_id)
                    if not isinstance(full_data, dict):
                        logger.warning(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: full_data –Ω–µ dict")
                        continue
                    text = html_to_text(full_data.get('content', ''))
                    metadata = full_data.get('metadata', {})
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
                    continue

            self._process_text(page_id, text, metadata)

            if idx % 100 == 0 or idx == total:
                logger.info(f"‚úÖ –ü—Ä–æ–≥—Ä–µ—Å—Å: {idx}/{total} ({100 * idx // total}%)")

        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(page_data_cache)} —Å—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ")

    def _process_text(self, page_id: str, text: str, metadata: Dict[str, Any]):
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        try:
            chunks = self.chunker.split(text)
            total_chunks = len(chunks)

            for num, chunk_text in enumerate(chunks):
                dense_vector = self.embedder.embed_text(chunk_text)
                sparse_vector = self.embedder.embed_sparse(chunk_text)
                chunk_id = f"{page_id}-{num}"

                chunk_metadata = {
                    **metadata,
                    'chunk_index': num,
                    'total_chunks': total_chunks
                }

                # ‚úÖ –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏
                chunk_metadata = {
                    k: v for k, v in chunk_metadata.items()
                    if not (isinstance(v, list) and len(v) == 0)
                }

                self.db.upsert_page(chunk_id, dense_vector, sparse_vector, chunk_text, chunk_metadata)

                current_time = datetime.now(timezone.utc)
                self.redis.setex(f'update_time:{page_id}', 86400 * 30, format_datetime(current_time))

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {page_id}: {e}")

    def sync_changed_pages(self, max_pages: int = None) -> dict:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        stats = {'checked': 0, 'updated': 0, 'new': 0, 'errors': 0}

        try:
            space_id = self.confluence_api.get_space_id()
            pages = self.confluence_api.get_page_ids(space_id)

            if max_pages:
                pages = dict(list(pages.items())[:max_pages])

            for page_id, page_info in pages.items():
                stats['checked'] += 1

                try:
                    confluence_time_str = self.confluence_api.get_time(page_id)
                    stored_time_str = self.redis.get(f'update_time:{page_id}')

                    need_update = False

                    if stored_time_str is None:
                        logger.info(f"üÜï –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page_info.get('title')}")
                        stats['new'] += 1
                        need_update = True
                    else:
                        confluence_time = parse_datetime(confluence_time_str)
                        stored_time = parse_datetime(stored_time_str)

                        if confluence_time and stored_time and confluence_time > stored_time:
                            logger.info(f"üîÑ –ò–∑–º–µ–Ω–µ–Ω–∞: {page_info.get('title')}")
                            need_update = True

                    if need_update:
                        if self.update_page(page_id, page_info):
                            stats['updated'] += 1

                except Exception as e:
                    logger.error(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_id}: {e}")
                    stats['errors'] += 1
                    continue

            logger.info(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {stats['updated']} –æ–±–Ω–æ–≤–ª–µ–Ω–æ, {stats['new']} –Ω–æ–≤—ã—Ö")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

        return stats

    def periodic_update(self, check_interval: int = 300, max_pages_per_cycle: int = 50):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        logger.info(f"üîÑ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {check_interval} —Å–µ–∫)...")

        while True:
            try:
                stats = self.sync_changed_pages(max_pages=max_pages_per_cycle)

                if stats['updated'] > 0:
                    logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']}/{stats['checked']}")
                else:
                    logger.info(f"‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ({stats['checked']} –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ)")

                logger.info(f"‚è≥ –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {check_interval} —Å–µ–∫...\n")
                time.sleep(check_interval)

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ periodic_update: {e}")
                time.sleep(check_interval)
